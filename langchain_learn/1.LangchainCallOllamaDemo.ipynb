{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 安装langchain\n",
    "2. 安装ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain\n",
    "! pip install -U langchain-ollama\n",
    "! pip install langchain_community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 引入LangChain聊天场景的提示词模板\n",
    "2. 进入ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引入LangChain的Ollama模块，用以集成Ollama的DeepSeek大模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化Ollama模型，此处以DeepSeek为例。\n",
    "llm = OllamaLLM(model=\"deepseek-r1:8b\")\n",
    "#llm.invoke(\"Who are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据message生成提示词模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "   (\"system\", \"你是世界级的技术专家\"),\n",
    "   (\"user\", \"{input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过langchain链式调用，生成一个chain\n",
    "基于LCEL表达式构建LLM链，lcel语法类似inux的pipeline语法，从左到右按顺序执行\n",
    "下面变拍了一个简单的工作流，后弦执行promt完成提示词模板格式化处理，然后调用llm模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "嗯，用户让我帮他写一篇关于AI的技术文章，要求100个字。首先，我得理解他的需求。他可能是一个学生或者需要简洁表达的人，不太确定具体用途，但内容要专业。\n",
      "\n",
      "然后，100个字其实不多，所以得精炼。我应该涵盖AI的主要特点，比如算法、数据分析，以及应用领域。同时，要提到对人类社会的影响，这样文章看起来更全面。\n",
      "\n",
      "考虑到用户可能希望文章有深度，但又不过于学术化，我需要用简洁明了的语言。比如，开头可以提到AI作为前沿技术，然后列举算法、数据分析，再讲应用和挑战。\n",
      "\n",
      "最后，要确保结尾部分提到对人类社会的深远影响，这样既有总结又有展望。这样整篇文章结构完整，又符合字数要求。\n",
      "</think>\n",
      "\n",
      "AI技术正在重新定义人类与智能的关系。通过强大的算法和数据分析能力，AI能够模拟人类思维并在多个领域展现出超凡性能，从医疗诊断到自动驾驶，再到个性化推荐，AI的应用无处不在。然而，这种技术进步也带来了新的挑战，如隐私保护、伦理争议和人工智能对社会的深远影响。如何在科学发展与人类文明保护之间寻找平衡，是我们需要共同面对的课题。\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "result = chain.invoke({\"input\":\"帮我写一篇文章AI的技术文章，100个字\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出转换\n",
    "LLM的输出通道是一条消息，为了更方便处理结果，可以将消息转换为字符串。下面展示如何将LLM的输出转换为字符串："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\n好，让我来分析一下用户的需求。用户希望我写一篇关于LangChain的文章，长度大约100字左右，并且表现出我作为“世界级的技术专家”。首先，我需要明确LangChain是什么，它是一种基于大语言模型的框架，用于构建更智能的对话系统，对吧？\\n\\n接下来，用户可能希望文章简洁有力，突出LangChain的重要性。我应该提到它如何结合知识库和生成模型，提升对话系统的性能，比如回答准确性和相关性。同时，还要强调其在企业中的应用价值，如自动化客服、智能助手等。\\n\\n我还需要考虑文章的结构，开头可以介绍LangChain是什么，然后说明它的核心技术，接着提到其优势，最后总结其未来前景。语言上要专业但不失简洁，让读者一目了然。\\n\\n另外，用户可能希望文章带有一定的深度，但又不超过100字，所以每个部分都需要精炼。例如，用“结合知识图谱和生成模型”来说明技术特点，用“提升问答系统的准确性和相关性”来强调效果，用“企业自动化客服、智能助手等领域”来指明应用场景。\\n\\n最后，结尾可以用一句总结性的句子，强调LangChain的重要性。整体上，要保持文章流畅，信息全面，同时符合字数限制。\\n</think>\\n\\n当然，我将为您写一篇关于LangChain的简短文章：\\n\\nLangChain是一款开源的深度学习框架，专注于构建更智能的对话系统。它通过结合知识图谱和生成模型，大幅提升了问答系统的准确性和相关性。在企业自动化客服、智能助手等领域具有广泛应用前景。作为技术专家，我强烈推荐LangChain，相信它会成为未来人工智能开发的重要工具。'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "#创建一个字符串输出解析器\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "#将输出解析器添加到LLM链中，跟前面的例子一样，区别是工作流编排，最后一步将llm模型输出的结果传递给输出解析器\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "# 调用LLM链\n",
    "chain.invoke({\"input\": \"帮我写一份langchain的文章，100个字\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
